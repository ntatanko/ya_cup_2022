{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4ab1b5-2b38-41d6-a64b-447ab39d8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import annoy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7b8750-e9fc-4d48-a6ce-4688c825fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _data.artist_data.compute_score import load_submission\n",
    "from _data.artist_data.ny_baseline import (\n",
    "    FeaturesLoader,\n",
    "    NT_Xent,\n",
    "    SimCLR,\n",
    "    SimCLR_infer,\n",
    "    TestLoader,\n",
    "    TrainLoader,\n",
    "    compute_dcg,\n",
    "    eval_submission,\n",
    "    get_ideal_dcg,\n",
    "    get_ranked_list,\n",
    "    inference,\n",
    "    position_discounter,\n",
    "    train_val_split,\n",
    "    save_submission\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048c8239-1036-4a0a-b932-8799a6bf1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sandbox.ny_base_experiments import BasicNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e2e00a-afb4-46b8-8873-6f5f8233bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d78997-e6d4-4070-bbc0-cc800b6540a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/app/_data/artist_data/\"\n",
    "test_dir = \"/app/_data/artist_data/test_features/\"\n",
    "mod_dir = \"/app/_data/artist_data/baseline/\"\n",
    "train = pd.read_csv(os.path.join(root_dir, \"train_meta.tsv\"), sep=\"\\t\")\n",
    "test = pd.read_csv(os.path.join(root_dir, \"test_meta.tsv\"), sep=\"\\t\")\n",
    "test[\"path\"] = test[\"archive_features_path\"].apply(\n",
    "    lambda x: os.path.join(root_dir, \"test_features\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a8c1a2-8a11-4ae3-9bf1-fa93e4fc25a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/app/_data/artist_data/subm_mod/exp_tanh_5/',\n",
       " '/app/_data/artist_data/subm_mod/exp_tanh_4/',\n",
       " '/app/_data/artist_data/subm_mod/exp_tanh_2/',\n",
       " '/app/_data/artist_data/subm_mod/exp_tanh_3/',\n",
       " '/app/_data/artist_data/subm_mod/exp_tanh_1/',\n",
       " '/app/_data/artist_data/subm_mod/exp_tanh_6/',\n",
       " '/app/_data/artist_data/subm_mod/exp_tanh_0/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_paths = glob.glob(\"/app/_data/artist_data/subm_mod/exp_tanh_[0-6]/\")\n",
    "mod_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78573704-72bc-49e5-871d-7916342eb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_list(embeds, top_size=100, annoy_num_trees=1024):\n",
    "    annoy_index = None\n",
    "    annoy2id = []\n",
    "    id2annoy = dict()\n",
    "    for track_id, track_embed in tqdm(embeds.items()):\n",
    "        id2annoy[track_id] = len(annoy2id)\n",
    "        annoy2id.append(track_id)\n",
    "        if annoy_index is None:\n",
    "            annoy_index = annoy.AnnoyIndex(len(track_embed), \"angular\")\n",
    "        annoy_index.add_item(id2annoy[track_id], track_embed)\n",
    "    annoy_index.build(annoy_num_trees, n_jobs=-1)\n",
    "    ranked_list = dict()\n",
    "    for track_id in tqdm(embeds.keys()):\n",
    "        candidates = annoy_index.get_nns_by_item(id2annoy[track_id], top_size + 1)[\n",
    "            1:\n",
    "        ]  # exclude trackid itself\n",
    "        candidates = list(filter(lambda x: x != id2annoy[track_id], candidates))\n",
    "        ranked_list[track_id] = [annoy2id[candidate] for candidate in candidates]\n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01943573-318e-409e-809e-0b1ee4252483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, device):\n",
    "    weights = torch.load(os.path.join(path, \"best_module.pt\"))\n",
    "    with open(os.path.join(path, \"args.json\"), \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    model = SimCLR_infer(\n",
    "        encoder=BasicNet(cfg[\"n_chahels\"], 128, 3), projection_dim=256\n",
    "    ).to(device)\n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9827739-de7a-48ac-98d6-3891458b6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for p in mod_paths:\n",
    "    models.append(load_model(path=p, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87bdc634-7015-4c3c-8feb-0d062de05fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_loader = FeaturesLoader(\n",
    "    features_dir_path=\"/app/_data/artist_data/test_features/\", meta_info=test, device=device, test=False, crop_size=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d79daa8-8d7e-42cb-ae83-a5aac76d8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = TestLoader(\n",
    "    features_loader=test_feature_loader, batch_size=256, features_size=(512, 60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e2da196-8528-4432-8e42-afebae1114ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 41377/41377 [00:48<00:00, 857.03it/s]\n",
      "100% 41377/41377 [00:44<00:00, 934.90it/s]\n",
      "100% 41377/41377 [00:44<00:00, 920.97it/s]\n",
      "100% 41377/41377 [00:45<00:00, 906.71it/s]\n",
      "100% 41377/41377 [00:44<00:00, 933.71it/s]\n",
      "100% 41377/41377 [00:45<00:00, 919.05it/s]\n",
      "100% 41377/41377 [00:45<00:00, 911.09it/s]\n"
     ]
    }
   ],
   "source": [
    "all_embeds = []\n",
    "for model in models:\n",
    "    embeds = inference(model, test_loader)\n",
    "    all_embeds.append(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2551236-5fdd-4416-aa09-2e233773d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 41377/41377 [00:02<00:00, 15216.29it/s]\n",
      "100% 41377/41377 [02:36<00:00, 264.61it/s]\n",
      "100% 41377/41377 [00:02<00:00, 14381.26it/s]\n",
      "100% 41377/41377 [02:36<00:00, 264.40it/s]\n",
      "100% 41377/41377 [00:03<00:00, 12121.70it/s]\n",
      "100% 41377/41377 [02:35<00:00, 265.65it/s]\n",
      "100% 41377/41377 [00:02<00:00, 13889.83it/s]\n",
      "100% 41377/41377 [02:37<00:00, 263.11it/s]\n",
      "100% 41377/41377 [00:02<00:00, 15573.55it/s]\n",
      "100% 41377/41377 [02:37<00:00, 262.59it/s]\n",
      "100% 41377/41377 [00:02<00:00, 15919.08it/s]\n",
      "100% 41377/41377 [02:38<00:00, 261.62it/s]\n",
      "100% 41377/41377 [00:02<00:00, 15836.89it/s]\n",
      "100% 41377/41377 [02:38<00:00, 261.24it/s]\n"
     ]
    }
   ],
   "source": [
    "all_subm = []\n",
    "for n, embeds in enumerate(all_embeds):\n",
    "    submission = get_ranked_list(embeds, 300, 128)\n",
    "    all_subm.append(submission)\n",
    "    # save_submission(\n",
    "    #     submission, f\"/app/_data/artist_data/ens_submissions/final_{n}.txt\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcab10-ff0f-47e9-a79f-48153f4ea9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from _data.artist_data.compute_score import load_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1294ad20-6440-45a0-a933-982825c24a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub7 = load_submission(input_path='/app/_data/artist_data/subm_mod/exp_tanh_7/submission_prj_1000_2831.txt', max_top_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "553ac144-ea6f-4f71-969b-abab759d6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efded3a9-d994-4170-87b3-0044c6f0917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subm.append(sub7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96cffff7-cf8d-4e14-80bf-c30a9de9bdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52b65757-e554-407e-97a1-ae601f9d5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = all_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31f7c2db-c6b1-4264-b3ec-3f0e6008459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 41377/41377 [25:56<00:00, 26.59it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_submission = {\n",
    "    \"mean\": {},\n",
    "    \"top4\": {},\n",
    "    \"top5\": {},\n",
    "    \"top6\": {},\n",
    "    \"top7\": {},\n",
    "    \"top8\": {},\n",
    "    \"mid\": {},\n",
    "}\n",
    "for trackid in tqdm(test[\"trackid\"].tolist()):\n",
    "    track_ranks = {}\n",
    "\n",
    "    all_tracks = np.zeros([8, 300])\n",
    "    for i in range(len(submissions)):\n",
    "        if len(submissions[i][trackid]) < 300:\n",
    "            submissions[i][trackid].append(0)\n",
    "        all_tracks[i] = submissions[i][trackid][:300]\n",
    "    values, counts = np.unique(\n",
    "        all_tracks,\n",
    "        return_index=False,\n",
    "        return_inverse=False,\n",
    "        return_counts=True,\n",
    "    )\n",
    "    values = values[counts >= 4]\n",
    "    names = [\"trackid\", \"count\", \"mean\", \"top4\", \"top5\", \"top6\", \"top7\", \"top8\", \"mid\"]\n",
    "    arr = np.zeros([values.shape[0], len(names)])\n",
    "    # df = pd.DataFrame()\n",
    "    for v in range(values.shape[0]):\n",
    "        rank = np.argwhere(all_tracks == values[v])[:, 1]\n",
    "        arr[v, 0] = values[v]  # trackid\n",
    "        arr[v, 1] = rank.shape[0]  # count\n",
    "        arr[v, 2] = rank.mean()  # mean\n",
    "        arr[v, 3] = np.sort(rank)[:4].mean()  # top4\n",
    "        arr[v, 4] = np.sort(rank)[:5].mean()  # top5\n",
    "        arr[v, 5] = np.sort(rank)[:6].mean()  # top6\n",
    "        arr[v, 6] = np.sort(rank)[:7].mean()  # top7\n",
    "        arr[v, 7] = np.sort(rank)[:8].mean()  # top8\n",
    "        arr[v, 8] = np.sort(rank)[1:-1].mean()  # mid\n",
    "#         df.loc[v, \"trackid\"] = values[v]\n",
    "#         df.loc[v, \"ids\"] = \" \".join(list(map(str, np.sort(rank))))\n",
    "#         df.loc[v, \"count\"] = rank.shape[0]\n",
    "#         df.loc[v, \"mean\"] = rank.mean()\n",
    "#         df.loc[v, \"top4\"] = np.sort(rank)[:4].mean()\n",
    "#         df.loc[v, \"top5\"] = np.sort(rank)[:5].mean()\n",
    "#         df.loc[v, \"top6\"] = np.sort(rank)[:6].mean()\n",
    "#         df.loc[v, \"top7\"] = np.sort(rank)[:7].mean()\n",
    "#         df.loc[v, \"top8\"] = np.sort(rank)[:8].mean()\n",
    "#         df.loc[v, \"median\"] = np.sort(rank)[1:-1].mean()\n",
    "\n",
    "#     df[\"trackid\"] = df[\"trackid\"].astype(\"int\")\n",
    "\n",
    "    avg_submission[\"top4\"][trackid] = arr[\n",
    "        np.lexsort((arr[:, names.index(\"mid\")], arr[:, names.index(\"top4\")]))\n",
    "    ][:, 0][:100].astype(\"int\")\n",
    "    avg_submission[\"top5\"][trackid] = arr[\n",
    "        np.lexsort((arr[:, names.index(\"mid\")], arr[:, names.index(\"top5\")]))\n",
    "    ][:, 0][:100].astype(\"int\")\n",
    "    avg_submission[\"top6\"][trackid] = arr[\n",
    "        np.lexsort((arr[:, names.index(\"mid\")], arr[:, names.index(\"top6\")]))\n",
    "    ][:, 0][:100].astype(\"int\")\n",
    "    # avg_submission[\"top7\"][trackid] = arr[\n",
    "    #     np.lexsort((arr[:, names.index(\"mid\")], arr[:, names.index(\"top7\")]))\n",
    "    # ][:, 0][:100].astype(\"int\")\n",
    "    # avg_submission[\"top8\"][trackid] = arr[\n",
    "    #     np.lexsort((arr[:, names.index(\"mid\")], arr[:, names.index(\"top8\")]))\n",
    "    # ][:, 0][:100].astype(\"int\")\n",
    "    # avg_submission[\"mean\"][trackid] = arr[\n",
    "    #     np.lexsort((arr[:, names.index(\"mid\")], arr[:, names.index(\"mean\")]))\n",
    "    # ][:, 0][:100].astype(\"int\")\n",
    "    avg_submission[\"mid\"][trackid] = arr[\n",
    "        np.lexsort((arr[:, names.index(\"top6\")], arr[:, names.index(\"mid\")]))\n",
    "    ][:, 0][:100].astype(\"int\")\n",
    "    # for n in [\"mean\", \"top4\", \"top5\", \"top6\", \"top7\",'top8']:\n",
    "    #     np.array_equal(df.sort_values(by=[n, \"median\"]).head(100)[\"trackid\"].values, np.array(avg_submission[n][trackid]))\n",
    "    # for n in [\"mean\", \"top4\", \"top5\", \"top6\", \"top7\", \"top8\", \"median\"]:\n",
    "    #     v = (\n",
    "    #         df.sort_values(by=[n, \"median\"])\n",
    "    #         .head(100)[\"ids\"]\n",
    "    #         .str.split()\n",
    "    #         .apply(lambda x: list(map(int, x)))\n",
    "    #         .values\n",
    "    #     )\n",
    "    #     s = []\n",
    "    #     for i in v:\n",
    "    #         s.extend(i)\n",
    "    #     s = list(set(s))\n",
    "    #     if max(s) > 500:\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb42dfac-49a9-412f-aa10-2ff0904ce79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(submission, submission_path, submission_name, top=100):\n",
    "    with open(os.path.join(submission_path, submission_name), \"w\") as f:\n",
    "        for query_trackid, result in submission.items():\n",
    "            f.write(\"{}\\t{}\\n\".format(query_trackid, \" \".join(map(str, result[:top]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63675c5b-fae0-4765-9230-87fc682a768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [ \"top4\", \"top5\", \"top6\", \"mid\"]:\n",
    "    save_submission(\n",
    "        avg_submission[n], \"/app/_data/artist_data/ens_submissions/\", f\"{n}_final.txt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0325459-8918-42ff-bd7d-70793b8e80b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0452fa-abb2-4938-bc65-3d6e62eec85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af9647-f67c-4be3-9ef1-838382d02ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c088d9-8e75-4ba2-8545-38fbdbe32e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a41b09-a15b-48d6-ac5a-bbe27a5e5d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71dd52-4954-4537-b729-633b4c671816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a9cb3-fbf8-4595-9baa-211d0d066812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64c1dd-cd16-44d2-b279-69267ab783ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a512fe6-9b82-4e1e-a29c-12f23d9cac64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed91d80-3817-4977-afa2-e269a08ee942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef63aee4-063d-4bb8-9e61-e6842eacf036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_val_split(train, 7, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3950e20d-be22-4f0e-8ca3-905954e990f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_floader = FeaturesLoader(\n",
    "    features_dir_path=\"/app/_data/artist_data/train_features/\",\n",
    "    meta_info=val_df,\n",
    "    test=False,\n",
    "    device=device,\n",
    "    crop_size=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf173d7-b23e-4f80-89be-a88a549db8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = TestLoader(\n",
    "    features_loader=val_floader, batch_size=256, features_size=(512, 60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43156e3f-2cfe-4ec1-b8d5-3c3040bcbcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_paths = glob.glob(\"/app/_data/artist_data/subm_mod/512_256_*sh*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e8e23e-a3cc-40b5-b5c0-ed59a7a36836",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_paths.append(\"/app/_data/artist_data/subm_mod/512_256_7_trans2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "868d8f1d-ebeb-4581-b8b1-e9a37e7b0577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/app/_data/artist_data/subm_mod/512_256_2_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_7_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_0_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_6_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_1_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_3_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_4_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_5_shuffle/',\n",
       " '/app/_data/artist_data/subm_mod/512_256_7_trans2/']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257539f-5f73-4e1a-8868-ac7267c58942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f16a565e-b67a-498d-85a8-ba9c4a87f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet1D(nn.Module):\n",
    "    def __init__(self, output_features_size1=512, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.output_features_size = output_features_size1\n",
    "        self.conv_1 = nn.Conv1d(\n",
    "            512, output_features_size1, kernel_size=kernel_size, padding=1\n",
    "        )\n",
    "        self.conv_2 = nn.Conv1d(\n",
    "            output_features_size1,\n",
    "            output_features_size1,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.mp_1 = nn.MaxPool1d(2, 2)\n",
    "        self.conv_3 = nn.Conv1d(\n",
    "            output_features_size1,\n",
    "            output_features_size1,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.conv_4 = nn.Conv1d(\n",
    "            output_features_size1,\n",
    "            output_features_size1,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = self.mp_1(x)\n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = self.conv_4(x).mean(axis=2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimCLR_infer(nn.Module):\n",
    "    def __init__(self, encoder, projection_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.n_features = encoder.output_features_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_features, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_features, self.projection_dim, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "    ):\n",
    "        x = self.encoder(x)\n",
    "        x = self.projector(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a2c56ae-d8e9-44e5-a306-38ce34c312ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, device):\n",
    "    weights = torch.load(os.path.join(path, \"best_module.pt\"))\n",
    "    with open(os.path.join(path, \"args.json\"), \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    if \"trans\" in path:\n",
    "        model = SimCLR_infer(\n",
    "            encoder=BasicNet(cfg[\"n_chahels\"], 128, 3), projection_dim=256\n",
    "        ).to(device)\n",
    "    else:\n",
    "        model = SimCLR_infer(\n",
    "            encoder=BasicNet1D(cfg[\"n_chahels\"], 3), projection_dim=256\n",
    "        ).to(device)\n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9daacad-d94c-49bd-a211-490576bb3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for p in mod_paths:\n",
    "    models.append(load_model(path=p, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1460cfb2-bf4b-4be3-82a8-568f947ef1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_inference(models, loader):\n",
    "    embeds = dict()\n",
    "    for n, model in enumerate(models):\n",
    "        for tracks_ids, tracks_features in loader:\n",
    "            with torch.no_grad():\n",
    "                tracks_embeds = model(tracks_features)\n",
    "                for track_id, track_embed in zip(tracks_ids, tracks_embeds):\n",
    "                    if track_id not in embeds.keys():\n",
    "                        embeds[track_id] = [track_embed.cpu().numpy()]\n",
    "                    else:\n",
    "                        embeds[track_id].append(track_embed.cpu().numpy())\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51434cee-4fea-44d5-8f4c-53e534c94130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20864/20864 [00:18<00:00, 1143.06it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1155.71it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1154.77it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1151.53it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1134.47it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1129.67it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1144.42it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1130.57it/s]\n",
      "100% 20864/20864 [00:18<00:00, 1144.28it/s]\n"
     ]
    }
   ],
   "source": [
    "embeds = ensemble_inference(models, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ae711fe-6d51-44f2-bfc7-aeb28d768fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_emb = {k: np.array(v).sum(0) for k,v in embeds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5870d52-e7ed-4f5e-b74c-c6dfd7ef4dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_emb[65336].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b33aedd-c479-46d5-8070-a3a54ddcac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20864/20864 [00:01<00:00, 15247.03it/s]\n",
      "100% 20864/20864 [02:32<00:00, 136.73it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = get_ranked_list(arr_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "943ecccd-e7d6-4f14-87da-6559874a63c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20864/20864 [00:07<00:00, 2711.01it/s]\n"
     ]
    }
   ],
   "source": [
    "ndcg = eval_submission(submission, gt_meta_info=val_df, top_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f40ebcf7-030a-4ba7-aad5-fc187ffe6c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3834791599111589"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52eb5294-aa21-43a2-9288-e7711eaf5269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.395118474378242"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b254932-5b6f-425b-bc15-2f34cd5daec6",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5750524c-69ce-4323-8b35-ad6e7fb06e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_loader = FeaturesLoader(\n",
    "    features_dir_path=\"/app/_data/artist_data/test_features/\", meta_info=test, device=device, test=False, crop_size=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f7c1220-b7bf-4dfa-baa9-f8832e3a61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = TestLoader(\n",
    "    features_loader=test_feature_loader, batch_size=256, features_size=(512, 60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3ba331a4-03fd-45f2-907d-da3375d06ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 41377/41377 [00:44<00:00, 920.97it/s]\n",
      "100% 41377/41377 [00:45<00:00, 914.24it/s]\n",
      "100% 41377/41377 [00:44<00:00, 937.89it/s] \n",
      "100% 41377/41377 [00:44<00:00, 928.18it/s]\n",
      "100% 41377/41377 [00:44<00:00, 928.08it/s] \n",
      "100% 41377/41377 [00:44<00:00, 936.67it/s]\n",
      "100% 41377/41377 [00:45<00:00, 917.77it/s] \n",
      "100% 41377/41377 [00:44<00:00, 937.61it/s] \n",
      "100% 41377/41377 [00:45<00:00, 909.47it/s]\n"
     ]
    }
   ],
   "source": [
    "test_embeds = ensemble_inference(models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6cdcf35-51b7-4227-b23a-e1f98a2e512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr_emb = {k: np.array(v).mean(0) for k,v in test_embeds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "902f004a-57d1-4469-87ba-b1c5555d487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 41377/41377 [00:02<00:00, 14155.49it/s]\n",
      "100% 41377/41377 [06:02<00:00, 114.18it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = get_ranked_list(test_arr_emb, 100, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "57288c0d-3a82-46f5-baf9-92e99d95b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(\n",
    "        submission, \"/app/_data/artist_data/ens_submissions/mod9_sum.txt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f2fbb-8fb9-4465-8a99-d36f2a8498dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
