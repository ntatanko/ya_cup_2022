{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0cfeb27-6927-40c4-a649-c845ae190f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random as rnd\n",
    "import shutil\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils import euclidean_distance, loss\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f37bfd-906a-4c82-9f02-e2a644f87e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.seed = 39\n",
    "        self.batch_size = 32\n",
    "        self.img_size = (512, 81)\n",
    "        self.n_chanels = 1\n",
    "        self.n_folds = 6\n",
    "        self.fold = 0\n",
    "        self.norm = False\n",
    "        self.pos_label = 0\n",
    "        self.n_blocks = 4\n",
    "        self.emb_len = 1024\n",
    "        self.kernel_size = (5, 2)\n",
    "        self.act_fn = \"relu\"\n",
    "        self.batch_norm = False\n",
    "        self.n_epochs = 1000\n",
    "        self.input_shape = (self.img_size[0], self.img_size[1], self.n_chanels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b1c6d8-6370-4f1d-8779-22f43825eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb03fdc-2eba-4ebc-b855-381fab371c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/app/_data/artist_data/\"\n",
    "mod_dir = \"/app/_data/artist_data/models/test_arch/constr_7/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96529f06-beba-40d2-b134-d228363cdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(root_dir, \"test_meta.tsv\"), sep=\"\\t\")\n",
    "test[\"path\"] = test[\"archive_features_path\"].apply(\n",
    "    lambda x: os.path.join(root_dir, \"test_features\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a4abe-fe3e-446f-95a3-e939dee079e4",
   "metadata": {},
   "source": [
    "## TestDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d043586b-e084-44ad-bea9-bfbc674d2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_size,\n",
    "        test=False,\n",
    "        batch_size=32,\n",
    "        norm=False,\n",
    "        n_chanels=1,\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.test = test\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.norm = norm\n",
    "        self.n_chanels = n_chanels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = np.load(path).astype(\"float32\")\n",
    "        if self.norm:\n",
    "            img -= img.min()\n",
    "            img /= img.max()\n",
    "        if img.shape != self.img_size:\n",
    "            wpad = self.img_size[1] - img.shape[1]\n",
    "            wpad_l = wpad // 2\n",
    "            wpad_r = wpad - wpad_l\n",
    "            img = np.pad(\n",
    "                img,\n",
    "                pad_width=((0, 0), (wpad_l, wpad_r)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=0,\n",
    "            )\n",
    "        img = np.expand_dims(img, -1)\n",
    "        if self.n_chanels == 3:\n",
    "            img = np.concatenate([img, img, img], -1)\n",
    "        return img\n",
    "\n",
    "    def _get_one(self, ix):\n",
    "        img_path, track_id = self.df.loc[ix, [\"path\", \"trackid\"]].values\n",
    "        img = self.load_img(img_path)\n",
    "        if not self.test:\n",
    "            artist_id = self.df.loc[ix, \"artistid\"]\n",
    "            return {\"img\": img, \"artist_id\": artist_id, \"track_id\": track_id}\n",
    "        else:\n",
    "            return {\"img\": img, \"track_id\": track_id}\n",
    "\n",
    "    def __getitem__(self, batch_ix):\n",
    "        imgs = np.zeros(\n",
    "            (self.batch_size, self.img_size[0], self.img_size[1], self.n_chanels),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        meta = {\"track_ids\": []}\n",
    "        if not self.test:\n",
    "            meta[\"artist_ids\"] = []\n",
    "        for i in range(self.batch_size):\n",
    "            data = self._get_one(ix=i + self.batch_size * batch_ix)\n",
    "            imgs[i] = data[\"img\"]\n",
    "            meta[\"track_ids\"].append(data[\"track_id\"])\n",
    "            if not self.test:\n",
    "                meta[\"artist_ids\"].append(data[\"artist_id\"])\n",
    "\n",
    "        return {\"imgs\": imgs, \"meta\": meta}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff85f4-22b6-42ad-8702-15c37f01b9a2",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0b1f94-0a94-4c0e-8e6e-637c95e25f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=cfg.input_shape, dtype=\"float32\", name=\"imgs\")\n",
    "x = keras.layers.Conv2D(\n",
    "    4,\n",
    "    cfg.kernel_size,\n",
    "    activation=cfg.act_fn,\n",
    "    name=\"Conv2D_1\",\n",
    ")(input)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(2, 2), name=f\"avg_pool_1\")(x)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=cfg.kernel_size,\n",
    "    activation=cfg.act_fn,\n",
    "    name=\"Conv2D_2\",\n",
    ")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(2, 2), name=f\"avg_pool_2\")(x)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=cfg.kernel_size,\n",
    "    activation=cfg.act_fn,\n",
    "    name=\"Conv2D_3\",\n",
    ")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(2, 2), name=f\"avg_pool_3\")(x)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=cfg.kernel_size,\n",
    "    activation=cfg.act_fn,\n",
    "    name=\"Conv2D_4\",\n",
    ")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(2, 2), name=f\"avg_pool_4\")(x)\n",
    "\n",
    "\n",
    "x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "x = keras.layers.Dense(cfg.emb_len, activation=cfg.act_fn, name=f\"dense_{cfg.emb_len}\")(\n",
    "    x\n",
    ")\n",
    "embedding_net = keras.Model(inputs=input, outputs=x, name=f\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bdaf40-2c8d-4a33-8703-1a979c02da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_len = 2048\n",
    "# mod_dir = \"/app/_data/artist_data/models/test_arch/constr_7/\"\n",
    "# mod = keras.models.load_model(\n",
    "#     os.path.join(mod_dir, \"model.h5\"), custom_objects={\"contrastive_loss\": loss(1)}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7307c11a-584b-4ed6-bd52-47e5519535e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# emb_len = 1024\n",
    "mod_dir = \"/app/_data/artist_data/models/test_arch/constr_8/model_879\"\n",
    "mod = keras.models.load_model(mod_dir, custom_objects={\"contrastive_loss\": loss(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02abcdbf-f997-4aa8-b96a-55acd4394dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net.set_weights(mod.weights[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c3d81-8a67-4bb8-b6aa-08cb4e4f5f9e",
   "metadata": {},
   "source": [
    "## feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6d7937-a3d0-4424-b0b7-2c0503bd6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_batch_size(data_size, max_size=550):\n",
    "    div = [1]\n",
    "    i = 2\n",
    "    while i <= data_size:\n",
    "        if data_size % i == 0:\n",
    "            div.append(i)\n",
    "        i += 1\n",
    "    div = np.array(div)\n",
    "    max_batch_size = np.max(np.where(div < max_size, div, 0))\n",
    "    return max_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8492b0ee-ab2e-42d5-b4a4-dc40533ca458",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = TestDataGenerator(\n",
    "    df=test,\n",
    "    img_size=cfg.img_size,\n",
    "    test=True,\n",
    "    batch_size=find_batch_size(test.shape[0]),\n",
    "    norm=False,\n",
    "    n_chanels=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6123ce2b-0cdf-4dfe-aac1-a253e31edd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['meta'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 58s 345ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = embedding_net.predict(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7bfccf5-3010-483a-905b-876f3405898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape[0] == test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab743a5-1dc7-46a6-bb93-bbb55aa09d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_100(\n",
    "    prediction,\n",
    "    df,\n",
    "    val=True,\n",
    "    path_to_save=\"/app/_data/artist_data/test_submissions\",\n",
    "    file_ix=1,\n",
    "):\n",
    "    dists = euclidean_distances(pred)\n",
    "    neigh = {}\n",
    "    with open(os.path.join(path_to_save, f\"submission_{file_ix}\"), \"w\") as f:\n",
    "        for ix in tqdm(range(prediction.shape[0])):\n",
    "            trackid = df.loc[ix, \"trackid\"]\n",
    "            nearest_100 = np.argsort(dists[ix])[:101]\n",
    "            tracks_100 = df.loc[nearest_100, \"trackid\"].tolist()\n",
    "            neigh[trackid] = {\"tracks\": [x for x in tracks_100 if x != trackid]}\n",
    "            if val:\n",
    "                artist_100 = df.loc[nearest_100, \"artistid\"].tolist()\n",
    "                neigh[trackid][\"artists\"] = tracks_100\n",
    "            f.write(\n",
    "                \"{}\\t{}\\n\".format(\n",
    "                    trackid,\n",
    "                    \" \".join(list(map(str, tracks_100))),\n",
    "                )\n",
    "            )\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6cbae29-87d2-4660-890e-d1de9687fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 41377/41377 [02:18<00:00, 299.63it/s]\n"
     ]
    }
   ],
   "source": [
    "neigh = choose_100(\n",
    "    prediction=pred,\n",
    "    df=test,\n",
    "    val=False,\n",
    "    path_to_save=os.path.join(root_dir, \"test_submissions\"),\n",
    "    file_ix=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "984a9e9b-e40a-4f8b-9812-e5e24cd612a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission(input_path, max_top_size=100):\n",
    "    result = {}\n",
    "    with open(input_path, \"r\") as finput:\n",
    "        for line in finput:\n",
    "            query_trackid, answer_items = line.rstrip().split(\"\\t\", 1)\n",
    "            query_trackid = int(query_trackid)\n",
    "            ranked_list = []\n",
    "            for result_trackid in answer_items.split(\" \"):\n",
    "                result_trackid = int(result_trackid)\n",
    "                if result_trackid != query_trackid:\n",
    "                    ranked_list.append(result_trackid)\n",
    "                if len(ranked_list) >= max_top_size:\n",
    "                    break\n",
    "            result[query_trackid] = ranked_list\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f6bc36d-db96-4262-a777-0b39e6ab70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = load_submission(\n",
    "    \"/app/_data/artist_data/test_submissions/submission_2\", max_top_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "694d5856-2634-49af-b729-9be232768c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1be8be-418f-4a5e-9675-1763a0b97944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
