{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14299a1d-8ec7-4ed0-96e1-ce81fa0af3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc23e1a-2855-48cb-956b-67a021d80f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random as rnd\n",
    "import shutil\n",
    "from itertools import combinations\n",
    "\n",
    "import albumentations as A\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.model_selection import StratifiedGroupKFold, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, activations, layers, losses\n",
    "from tensorflow.keras.utils import Progbar, plot_model\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tqdm import tqdm\n",
    "\n",
    "from _data.artist_data.ny_baseline import eval_submission as ev_sub\n",
    "from _data.artist_data.ny_baseline import get_ranked_list, inference\n",
    "from src.test_utils import (\n",
    "    TestGenerator,\n",
    "    choose_100,\n",
    "    eval_submission,\n",
    "    load_submission,\n",
    "    pairwise_distances,\n",
    ")\n",
    "from src.utils import make_callbacks, plot_history\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d841314c-f269-4b69-89fd-f726d78bb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.seed = 39\n",
    "        self.batch_size = 8\n",
    "        self.img_size = (512, 60)\n",
    "        self.n_folds = 8\n",
    "        self.fold = 0\n",
    "        self.norm = False\n",
    "        self.n_blocks = 4\n",
    "        self.emb_len = 1024\n",
    "        self.kernel_size = (5, 2)\n",
    "        self.batch_norm = False\n",
    "        self.n_epochs = 300\n",
    "        self.n_pairs_in_batch = 100\n",
    "        self.input_shape = (self.img_size[0], self.img_size[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93f6112-f03e-4df9-8e75-77aade00c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d157d3-7015-4828-bc9d-d688dfbafb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/_data/artist_data/models/test_arch/tripl_semi_hard_8_0/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"/app/_data/artist_data/\"\n",
    "mod_dir = f\"/app/_data/artist_data/models/test_arch/tripl_semi_hard_8_{cfg.fold}/\"\n",
    "mod_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46771e08-5acb-444d-a2b9-bb6bb8f4df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(root_dir, \"train.csv\"))\n",
    "train = train[train[\"artistid_count\"] != 1].reset_index(drop=True)\n",
    "test = pd.read_csv(os.path.join(root_dir, \"test_meta.tsv\"), sep=\"\\t\")\n",
    "test[\"path\"] = test[\"archive_features_path\"].apply(\n",
    "    lambda x: os.path.join(root_dir, \"test_features\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b35fc-281b-4c45-afb4-286bfd2eef13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e5bb09-cd8b-4cc3-af39-acc73ee0b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = StratifiedGroupKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "for n, (train_ids, val_ids) in enumerate(\n",
    "    gkf.split(\n",
    "        X=train[[\"artistid\", \"artistid_count\"]],\n",
    "        y=train[\"artistid_count\"],\n",
    "        groups=train[\"artistid\"],\n",
    "    )\n",
    "):\n",
    "    train.loc[val_ids, \"fold\"] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6761a2-a078-4863-a487-dd397cd1f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[train[\"fold\"] != cfg.fold].reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == cfg.fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aae54a-8be1-48e7-b74a-fb519b745a3f",
   "metadata": {},
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0ef5c5-7498-4652-be03-44a48be62df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        img_size,\n",
    "        batch_size=32,\n",
    "        n_pairs_in_batch=50,\n",
    "        norm=False,\n",
    "        shuffle=True,\n",
    "        transpose=True,\n",
    "        augment=True,\n",
    "    ):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_pairs_in_batch = n_pairs_in_batch\n",
    "        self.norm = norm\n",
    "        self.shuffle = shuffle\n",
    "        self.transpose = transpose\n",
    "        self.augment = augment\n",
    "        self.artist_ids = self.data[\"artistid\"].unique().tolist()\n",
    "        self.artis2path = self.data.groupby(\"artistid\").agg(list)[\"path\"].to_dict()\n",
    "        self.paths = self.data[\"path\"].tolist()\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.artist_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def augment_fn(self, img):\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.RandomCrop(always_apply=True, p=1.0, height=512, width=60),\n",
    "                A.Flip(p=0.2),\n",
    "                A.PixelDropout(p=0.1, dropout_prob=0.01),\n",
    "                A.CoarseDropout(\n",
    "                    p=0.1,\n",
    "                    max_holes=11,\n",
    "                    max_height=5,\n",
    "                    max_width=3,\n",
    "                    min_holes=1,\n",
    "                    min_height=2,\n",
    "                    min_width=2,\n",
    "                ),\n",
    "                A.RandomGridShuffle(p=0.3, grid=(1, 6)),\n",
    "            ]\n",
    "        )\n",
    "        return transform(image=img)[\"image\"]\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = np.load(path).astype(\"float32\")\n",
    "        if self.norm:\n",
    "            img -= img.min()\n",
    "            img /= img.max()\n",
    "        if self.augment:\n",
    "            img = self.augment_fn(img)\n",
    "        else:\n",
    "            wpad = (img.shape[1] - self.img_size[1]) // 2\n",
    "            img = img[:, wpad : wpad + self.img_size[1]]\n",
    "        if self.transpose:\n",
    "            img = img.transpose(1, 0)\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "\n",
    "    def get_list(self, artis_id):\n",
    "        valid_paths = self.artis2path[artis_id]\n",
    "        np.random.shuffle(valid_paths)\n",
    "        anchor_img = np.expand_dims(self.load_img(valid_paths[0]), 0)\n",
    "        positive_imgs = np.array([self.load_img(p) for p in valid_paths[1:]])\n",
    "        negative_paths = rnd.sample(\n",
    "            [x for x in self.paths if x not in valid_paths],\n",
    "            self.n_pairs_in_batch - len(positive_imgs),\n",
    "        )\n",
    "        negative_imgs = np.array([self.load_img(p) for p in negative_paths])\n",
    "        imgs = np.concatenate([positive_imgs, negative_imgs])\n",
    "        labels = np.full(self.n_pairs_in_batch, 10)\n",
    "        labels[positive_imgs.shape[0] :] = 0\n",
    "        perm = np.random.permutation(self.n_pairs_in_batch)\n",
    "        imgs = imgs[perm]\n",
    "        labels = labels[perm]\n",
    "        imgs = np.concatenate([anchor_img, imgs])\n",
    "        return imgs, labels\n",
    "\n",
    "    def __call__(self):\n",
    "        np.random.shuffle(self.artist_ids)\n",
    "        ix = 0\n",
    "        while ix < len(self.artist_ids):\n",
    "            tracks, labels = self.get_list(self.artist_ids[ix])\n",
    "            tracks = tf.convert_to_tensor(tracks)\n",
    "            labels = tf.convert_to_tensor(labels)\n",
    "            yield tracks, labels\n",
    "            ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e016b9-01bc-4a06-a8ba-0b308faa8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    data=train_df,\n",
    "    img_size=cfg.img_size,\n",
    "    batch_size=cfg.batch_size,\n",
    "    n_pairs_in_batch=cfg.n_pairs_in_batch,\n",
    "    norm=False,\n",
    "    shuffle=True,\n",
    "    transpose=False,\n",
    "    augment=True,\n",
    ")\n",
    "val_gen = DataGenerator(\n",
    "    data=val_df,\n",
    "    img_size=cfg.img_size,\n",
    "    batch_size=cfg.batch_size,\n",
    "    n_pairs_in_batch=cfg.n_pairs_in_batch,\n",
    "    norm=False,\n",
    "    shuffle=True,\n",
    "    transpose=False,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fadce01-aebc-4b7f-aa84-f1140fc3d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 512, 60, 1) (100,)\n",
      "(101, 512, 60, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "for n, (a, b) in enumerate(train_gen.__call__()):\n",
    "    print(a.shape, b.shape)\n",
    "    if n == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb38b1ac-16ed-498f-937d-7020c634f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(101, 512, 60, 1), dtype=tf.float32, name='tracks'), TensorSpec(shape=(100,), dtype=tf.float32, name='labels'))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    train_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch + 1, *cfg.img_size, 1),\n",
    "            dtype=tf.float32,\n",
    "            name=\"tracks\",\n",
    "        ),\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch),\n",
    "            dtype=tf.float32,\n",
    "            name=\"labels\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    val_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch + 1, *cfg.img_size, 1),\n",
    "            dtype=tf.float32,\n",
    "            name=\"tracks\",\n",
    "        ),\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch),\n",
    "            dtype=tf.float32,\n",
    "            name=\"labels\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac82bfb7-3d67-4c56-b461-56d8b243965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0a2ce2-341d-498f-a77a-df079e568987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(101, 512, 60, 1), dtype=tf.float32, name='tracks'), TensorSpec(shape=(100,), dtype=tf.float32, name='labels'))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ade480a-cb01-41b3-b63c-e7ec99c9fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 512, 60, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "for example in train_ds.take(1):\n",
    "    print(example[0].shape, example[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3102230-894b-42e2-939c-715ca9cc82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embNet(\n",
    "    input_shape,\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.1,\n",
    "    embedding_len=1024,\n",
    "    activation_fn=\"relu\",\n",
    "    padding=\"same\",\n",
    "    dense_activation=\"relu\",\n",
    "):\n",
    "    base_model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                input_shape=input_shape,\n",
    "                padding=padding,\n",
    "                name=\"conv_1\",\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_2\",\n",
    "            ),\n",
    "            keras.layers.Dropout(rate=dropout_rate, name=\"dropout1\"),\n",
    "            keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2), strides=1, padding=\"same\", name=\"max_1\"\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_3\",\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_4\",\n",
    "            ),\n",
    "            keras.layers.Flatten(name=\"flatten_base\"),\n",
    "            keras.layers.Dense(embedding_len * 2, activation=\"relu\", name=\"dense_1\"),\n",
    "            keras.layers.Dense(embedding_len, activation=None, name=\"dense_base_2\"),\n",
    "        ]\n",
    "    )\n",
    "    embedding_net = keras.Model(\n",
    "        inputs=base_model.input, outputs=base_model.output, name=\"embedding\"\n",
    "    )\n",
    "    return embedding_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb5ead15-f608-4821-9211-00f21caf1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = embNet(\n",
    "    input_shape=(512, 60, 1),\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.1,\n",
    "    embedding_len=1024,\n",
    "    activation_fn=\"relu\",\n",
    "    padding=\"valid\",\n",
    "    dense_activation=\"relu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3508bb7d-877a-4897-83b0-853daaa2f8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([101, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = embedding_net(example[0])\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ae5b58b-ea6e-473e-b051-16253e469ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_embeddings = emb[:1]\n",
    "img_embeddings = emb[1:]\n",
    "anchors_embeddings.shape\n",
    "list_length = img_embeddings.shape[0]\n",
    "anchors_embedding_repeated = tf.repeat(anchors_embeddings, [list_length], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4205120-3ae6-4e9c-8e94-bb6553022dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1024])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_embedding_repeated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60d184b4-147e-4ba2-87e1-47aae8312ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1024])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 2048])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_embedding_repeated.shape\n",
    "\n",
    "concatenated_embeddings = tf.concat([anchors_embedding_repeated, img_embeddings], 1)\n",
    "\n",
    "concatenated_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "499492af-5c11-4370-ba82-9a8f6e9146d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = tf.keras.Sequential(\n",
    "    [\n",
    "        # Learn multiple dense layers.\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        # Make rating predictions in the final layer.\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores = score_model(concatenated_embeddings)\n",
    "\n",
    "scores.shape\n",
    "\n",
    "scores[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f659548-3f6f-4c9b-a099-4565a90cf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tfr.keras.losses.ListMLELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71977492-6f93-4e56-8194-4a305fe96458",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Ranking(\n",
    "    loss=loss,\n",
    "    metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d76d6f47-b0db-4237-8059-6272778d13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(scores, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6182b2c6-04e2-4f49-adcd-bd237e46f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([ 0., 10.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., 10.,  0., 10.,  0.,  0.,  0., 10.,  0., 10., 10.,  0.,  0.,\n",
       "        0., 10., 10.,  0.], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f5b1f29-282a-4d19-80c1-fbeaa7186217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(input_tensor=example[1], axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65b8d6b9-1fe7-47ab-8ebd-78a78e828b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=74.65823>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task(\n",
    "    labels=tf.expand_dims(example[1], 0),\n",
    "    predictions=tf.expand_dims(tf.squeeze(scores, axis=-1),0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3f9dd6-8443-4435-8625-07399c5764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.Model):\n",
    "    def __init__(self, loss, emb_model):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # embeddings model\n",
    "        self.embeddings = emb_model\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.score_model = tf.keras.Sequential(\n",
    "            [\n",
    "                # Learn multiple dense layers.\n",
    "                tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                # Make rating predictions in the final layer.\n",
    "                tf.keras.layers.Dense(1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=loss,\n",
    "            metrics=[\n",
    "                tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "                tf.keras.metrics.RootMeanSquaredError(),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        # batch_anchors = features[:1]\n",
    "        # batch_tracks = features[1:]\n",
    "        # We first convert the id features into embeddings.\n",
    "        # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "        embeddings = self.embeddings(features)\n",
    "        anchors_embeddings = embeddings[:1, ...]\n",
    "        img_embeddings = embeddings[1:, ...]\n",
    "        # anchors_embeddings = self.embeddings(batch_anchors)\n",
    "\n",
    "        # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "        # tensor.\n",
    "        # img_embeddings = tf.convert_to_tensor(\n",
    "        #     [self.embeddings(x) for x in batch_tracks]\n",
    "        # )\n",
    "\n",
    "        # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "        # them into the ranking model. To do so, we need to reshape the user\n",
    "        # embeddings to match the shape of movie embeddings.\n",
    "\n",
    "        list_length = img_embeddings.shape[0]\n",
    "        anchors_embedding_repeated = tf.repeat(\n",
    "            anchors_embeddings, [list_length], axis=0\n",
    "        )\n",
    "\n",
    "        # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "        # predictions.\n",
    "        concatenated_embeddings = tf.concat(\n",
    "            [anchors_embedding_repeated, img_embeddings], 1\n",
    "        )\n",
    "\n",
    "        return self.score_model(concatenated_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        # labels = features[\"labels\"]\n",
    "        scores = self(features)\n",
    "\n",
    "        return self.task(\n",
    "            labels=tf.expand_dims(labels, 0),\n",
    "            predictions=tf.expand_dims(tf.squeeze(scores, axis=-1), 0),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ef84d6-9a11-47a1-b9c0-46499a66447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss(), embedding_net)\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceaea417-598e-43ca-bfff-1993d93fe0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = RankingModel(tf.keras.losses.MeanSquaredError(), embedding_net)\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be881e-3acd-47ed-8519-9f5c2a2f2547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2125/146356 [..............................] - ETA: 5:52:24 - ndcg_metric: 0.4224 - root_mean_squared_error: 2.7286 - loss: 7.4450 - regularization_loss: 0.0000e+00 - total_loss: 7.4450"
     ]
    }
   ],
   "source": [
    "history = mse_model.fit(\n",
    "    x=train_ds,\n",
    "    epochs=10,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    steps_per_epoch=train_gen.__len__(),\n",
    "    validation_steps=val_gen.__len__(),\n",
    "    validation_freq=1,\n",
    "    max_queue_size=100,\n",
    "    workers=64,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afa492-d0cb-4513-8ad5-e6f679ff5559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
