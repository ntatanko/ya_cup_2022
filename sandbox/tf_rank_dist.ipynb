{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc23e1a-2855-48cb-956b-67a021d80f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rnd\n",
    "\n",
    "import albumentations as A\n",
    "import annoy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "from _data.artist_data.ny_baseline import eval_submission as ev_sub\n",
    "from _data.artist_data.ny_baseline import get_ranked_list\n",
    "from src.utils import make_callbacks\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d841314c-f269-4b69-89fd-f726d78bb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.seed = 39\n",
    "        self.img_size = (512, 60)\n",
    "        self.n_folds = 8\n",
    "        self.fold = 0\n",
    "        self.norm = False\n",
    "        self.emb_len = 1024\n",
    "        self.kernel_size = (5, 2)\n",
    "        self.n_epochs = 30\n",
    "        self.n_pairs_in_batch = 30\n",
    "        self.input_shape = (self.img_size[0], self.img_size[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93f6112-f03e-4df9-8e75-77aade00c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d157d3-7015-4828-bc9d-d688dfbafb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/_data/artist_data/models/test_arch/rank_dist_0/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"/app/_data/artist_data/\"\n",
    "mod_dir = f\"/app/_data/artist_data/models/test_arch/rank_dist_{cfg.fold}/\"\n",
    "mod_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46771e08-5acb-444d-a2b9-bb6bb8f4df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(root_dir, \"train.csv\"))\n",
    "train = train[train[\"artistid_count\"] != 1].reset_index(drop=True)\n",
    "test = pd.read_csv(os.path.join(root_dir, \"test_meta.tsv\"), sep=\"\\t\")\n",
    "test[\"path\"] = test[\"archive_features_path\"].apply(\n",
    "    lambda x: os.path.join(root_dir, \"test_features\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42341a80-d6bf-4947-9b86-9efcf3b839bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e5bb09-cd8b-4cc3-af39-acc73ee0b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = StratifiedGroupKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "for n, (train_ids, val_ids) in enumerate(\n",
    "    gkf.split(\n",
    "        X=train[[\"artistid\", \"artistid_count\"]],\n",
    "        y=train[\"artistid_count\"],\n",
    "        groups=train[\"artistid\"],\n",
    "    )\n",
    "):\n",
    "    train.loc[val_ids, \"fold\"] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6761a2-a078-4863-a487-dd397cd1f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[train[\"fold\"] != cfg.fold].reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == cfg.fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8b86b-f5a9-4835-a41a-f3ed44cd3b8b",
   "metadata": {},
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0ef5c5-7498-4652-be03-44a48be62df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        img_size,\n",
    "        n_pairs_in_batch=50,\n",
    "        norm=False,\n",
    "        shuffle=True,\n",
    "        transpose=True,\n",
    "        augment=True,\n",
    "    ):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.img_size = img_size\n",
    "        self.n_pairs_in_batch = n_pairs_in_batch\n",
    "        self.norm = norm\n",
    "        self.shuffle = shuffle\n",
    "        self.transpose = transpose\n",
    "        self.augment = augment\n",
    "        self.artist_ids = self.data[\"artistid\"].unique().tolist()\n",
    "        self.artis2path = self.data.groupby(\"artistid\").agg(list)[\"path\"].to_dict()\n",
    "        self.paths = self.data[\"path\"].tolist()\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.artist_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.artist_ids)\n",
    "\n",
    "    def augment_fn(self, img):\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.RandomCrop(always_apply=True, p=1.0, height=512, width=60),\n",
    "                A.Flip(p=0.2),\n",
    "                A.PixelDropout(p=0.1, dropout_prob=0.01),\n",
    "                A.CoarseDropout(\n",
    "                    p=0.1,\n",
    "                    max_holes=11,\n",
    "                    max_height=5,\n",
    "                    max_width=3,\n",
    "                    min_holes=1,\n",
    "                    min_height=2,\n",
    "                    min_width=2,\n",
    "                ),\n",
    "                A.RandomGridShuffle(p=0.3, grid=(1, 6)),\n",
    "            ]\n",
    "        )\n",
    "        return transform(image=img)[\"image\"]\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = np.load(path).astype(\"float32\")\n",
    "        if self.norm:\n",
    "            img -= img.min()\n",
    "            img /= img.max()\n",
    "        if self.augment:\n",
    "            img = self.augment_fn(img)\n",
    "        else:\n",
    "            wpad = (img.shape[1] - self.img_size[1]) // 2\n",
    "            img = img[:, wpad : wpad + self.img_size[1]]\n",
    "        if self.transpose:\n",
    "            img = img.transpose(1, 0)\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "\n",
    "    def get_list(self, artist_id):\n",
    "        valid_paths = self.artis2path[artist_id]\n",
    "        np.random.shuffle(valid_paths)\n",
    "        anchor_img = np.expand_dims(self.load_img(valid_paths[0]), 0)\n",
    "        positive_imgs = np.array([self.load_img(p) for p in valid_paths[1:]])\n",
    "        negative_paths = rnd.sample(\n",
    "            [x for x in self.paths if x not in valid_paths],\n",
    "            self.n_pairs_in_batch - len(positive_imgs),\n",
    "        )\n",
    "        negative_imgs = np.array([self.load_img(p) for p in negative_paths])\n",
    "        imgs = np.concatenate([positive_imgs, negative_imgs])\n",
    "        labels = np.zeros(self.n_pairs_in_batch)\n",
    "        labels[positive_imgs.shape[0] :] = 1\n",
    "        perm = np.random.permutation(self.n_pairs_in_batch)\n",
    "        imgs = imgs[perm]\n",
    "        labels = labels[perm]\n",
    "        imgs = np.concatenate([anchor_img, imgs])\n",
    "        return imgs, labels\n",
    "\n",
    "    def __call__(self):\n",
    "        np.random.shuffle(self.artist_ids)\n",
    "        ix = 0\n",
    "        while ix < len(self.artist_ids):\n",
    "            tracks, labels = self.get_list(self.artist_ids[ix])\n",
    "            tracks = tf.convert_to_tensor(tracks)\n",
    "            labels = tf.convert_to_tensor(labels)\n",
    "            yield tracks, labels\n",
    "            ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e016b9-01bc-4a06-a8ba-0b308faa8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    data=train_df,\n",
    "    img_size=cfg.img_size,\n",
    "    n_pairs_in_batch=cfg.n_pairs_in_batch,\n",
    "    norm=False,\n",
    "    shuffle=True,\n",
    "    transpose=False,\n",
    "    augment=True,\n",
    ")\n",
    "val_gen = DataGenerator(\n",
    "    data=val_df,\n",
    "    img_size=cfg.img_size,\n",
    "    n_pairs_in_batch=cfg.n_pairs_in_batch,\n",
    "    norm=False,\n",
    "    shuffle=True,\n",
    "    transpose=False,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb38b1ac-16ed-498f-937d-7020c634f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    train_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch + 1, *cfg.img_size, 1),\n",
    "            dtype=tf.float32,\n",
    "            name=\"tracks\",\n",
    "        ),\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch),\n",
    "            dtype=tf.float32,\n",
    "            name=\"labels\",\n",
    "        ),\n",
    "    ),\n",
    ").repeat()\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    val_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch + 1, *cfg.img_size, 1),\n",
    "            dtype=tf.float32,\n",
    "            name=\"tracks\",\n",
    "        ),\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch),\n",
    "            dtype=tf.float32,\n",
    "            name=\"labels\",\n",
    "        ),\n",
    "    ),\n",
    ").repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3102230-894b-42e2-939c-715ca9cc82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embNet(\n",
    "    input_shape,\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.1,\n",
    "    embedding_len=1024,\n",
    "    activation_fn=\"relu\",\n",
    "    padding=\"same\",\n",
    "):\n",
    "    base_model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                input_shape=input_shape,\n",
    "                padding=padding,\n",
    "                name=\"conv_1\",\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_2\",\n",
    "            ),\n",
    "            keras.layers.Dropout(rate=dropout_rate, name=\"dropout1\"),\n",
    "            keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2), strides=1, padding=\"same\", name=\"max_1\"\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_3\",\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_4\",\n",
    "            ),\n",
    "            keras.layers.Flatten(name=\"flatten_base\"),\n",
    "            keras.layers.Dense(embedding_len * 2, activation=\"relu\", name=\"dense_1\"),\n",
    "            keras.layers.Dense(embedding_len, activation=\"relu\", name=\"dense_base_2\"),\n",
    "        ]\n",
    "    )\n",
    "    embedding_net = keras.Model(\n",
    "        inputs=base_model.input, outputs=base_model.output, name=\"embedding\"\n",
    "    )\n",
    "    return embedding_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5ead15-f608-4821-9211-00f21caf1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = embNet(\n",
    "    input_shape=(512, 60, 1),\n",
    "    kernel_size=5,\n",
    "    dropout_rate=0.1,\n",
    "    embedding_len=1024,\n",
    "    activation_fn=\"relu\",\n",
    "    padding=\"valid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff3f9dd6-8443-4435-8625-07399c5764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(keras.Model):\n",
    "    def __init__(self, emb_model):\n",
    "        super().__init__()\n",
    "        self.embeddings = emb_model\n",
    "\n",
    "    def distance(self, y_true, y_pred):\n",
    "        dist = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)\n",
    "        # dist = tf.sqrt(tf.reduce_sum(tf.square(y_true - y_pred),axis=- 1))\n",
    "        return dist\n",
    "\n",
    "    def call(self, features):\n",
    "        embeddings = self.embeddings(features)\n",
    "        anchors_embeddings = embeddings[:1, ...]\n",
    "        img_embeddings = embeddings[1:, ...]\n",
    "        list_length = img_embeddings.shape[0]\n",
    "        anchors_embedding_repeated = tf.repeat(\n",
    "            anchors_embeddings, [list_length], axis=0\n",
    "        )\n",
    "        distances = self.distance(anchors_embedding_repeated, img_embeddings)\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0895f234-6000-4f7c-8f25-86fcd2b5a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_callbacks(\n",
    "    path, monitor=\"val_loss\", mode=\"min\", reduce_patience=3, stop_patience=20\n",
    "):\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=monitor,\n",
    "            patience=stop_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode=mode,\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(path, \"best\"),\n",
    "            monitor=monitor,\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            mode=mode,\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=monitor,\n",
    "            factor=0.9,\n",
    "            patience=reduce_patience,\n",
    "            verbose=1,\n",
    "            mode=mode,\n",
    "            min_delta=1e-4,\n",
    "            min_lr=0.00000001,\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=f\"/app/.tensorboard/{path.split('/')[-2]}/\", histogram_freq=0\n",
    "        ),\n",
    "        keras.callbacks.BackupAndRestore(os.path.join(path, \"backup\")),\n",
    "        keras.callbacks.TerminateOnNaN(),\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d424384-8895-4878-a92a-fc47b65fc0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "calbacks = make_callbacks(\n",
    "    \"/app/_data/rank_mod/\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    reduce_patience=2,\n",
    "    stop_patience=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c313d73-3d75-473e-8f53-960fe5f58e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankingModel(embedding_net)\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19be881e-3acd-47ed-8519-9f5c2a2f2547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.5665\n",
      "Epoch 1: val_loss improved from inf to 0.48655, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 330s 109ms/step - loss: 0.5665 - val_loss: 0.4866 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4809\n",
      "Epoch 2: val_loss improved from 0.48655 to 0.45806, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 321s 107ms/step - loss: 0.4809 - val_loss: 0.4581 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4550\n",
      "Epoch 3: val_loss improved from 0.45806 to 0.44825, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 324s 108ms/step - loss: 0.4550 - val_loss: 0.4482 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4490\n",
      "Epoch 4: val_loss improved from 0.44825 to 0.44139, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 321s 107ms/step - loss: 0.4490 - val_loss: 0.4414 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4416\n",
      "Epoch 5: val_loss improved from 0.44139 to 0.43088, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 322s 107ms/step - loss: 0.4416 - val_loss: 0.4309 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4323\n",
      "Epoch 6: val_loss improved from 0.43088 to 0.42525, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 325s 108ms/step - loss: 0.4323 - val_loss: 0.4252 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4363\n",
      "Epoch 7: val_loss did not improve from 0.42525\n",
      "3000/3000 [==============================] - 322s 107ms/step - loss: 0.4363 - val_loss: 0.4263 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4327\n",
      "Epoch 8: val_loss did not improve from 0.42525\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "3000/3000 [==============================] - 315s 105ms/step - loss: 0.4327 - val_loss: 0.4293 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4289\n",
      "Epoch 9: val_loss did not improve from 0.42525\n",
      "3000/3000 [==============================] - 317s 106ms/step - loss: 0.4289 - val_loss: 0.4259 - lr: 9.0000e-04\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.4252\n",
      "Epoch 10: val_loss improved from 0.42525 to 0.42341, saving model to /app/_data/rank_mod/best\n",
      "3000/3000 [==============================] - 324s 108ms/step - loss: 0.4252 - val_loss: 0.4234 - lr: 9.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_ds,\n",
    "    epochs=100,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=calbacks,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    steps_per_epoch=3000,\n",
    "    validation_steps=1000,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=100,\n",
    "    workers=64,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc6cb1-c392-4ae0-b8f3-9f359ef1639a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e9092-55d4-427c-a6d4-59abe7f370f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516ab481-04cc-4d24-a1b5-50f8544488c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        img_size,\n",
    "    ):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.img_size = img_size\n",
    "        self.track2path = self.data.set_index(\"trackid\")[\"path\"].to_dict()\n",
    "        self.tracks = self.data[\"trackid\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = np.load(path).astype(\"float32\")\n",
    "        wpad = (img.shape[1] - self.img_size[1]) // 2\n",
    "        img = img[:, wpad : wpad + self.img_size[1]]\n",
    "        img = np.expand_dims(img, [0, -1])\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        track = self.tracks[ix]\n",
    "        img = self.load_img(self.track2path[track])\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d68b810b-140d-4986-a1a9-9c171f7c8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = TestGenerator(val_df, (512, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b4a1a93-b294-4931-bd08-85e86474a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net.set_weights(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "146509d7-df3d-4bf6-9c6e-b537a3c9c797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20837/20837 [==============================] - 54s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = embedding_net.predict(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ae97c61-69cb-4703-8be2-5d9cb9404f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_discounter(position):\n",
    "    return 1.0 / np.log2(position + 1)\n",
    "\n",
    "\n",
    "def get_ideal_dcg(relevant_items_count, top_size):\n",
    "    dcg = 0.0\n",
    "    for result_indx in range(min(top_size, relevant_items_count)):\n",
    "        position = result_indx + 1\n",
    "        dcg += position_discounter(position)\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def compute_dcg(query_trackid, ranked_list, track2artist_map, top_size):\n",
    "    query_artistid = track2artist_map[query_trackid]\n",
    "    dcg = 0.0\n",
    "    for result_indx, result_trackid in enumerate(ranked_list[:top_size]):\n",
    "        assert result_trackid != query_trackid\n",
    "        position = result_indx + 1\n",
    "        discounted_position = position_discounter(position)\n",
    "        result_artistid = track2artist_map[result_trackid]\n",
    "        if result_artistid == query_artistid:\n",
    "            dcg += discounted_position\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def eval_submission(submission, gt_meta_info, top_size=100):\n",
    "    track2artist_map = gt_meta_info.set_index(\"trackid\")[\"artistid\"].to_dict()\n",
    "    artist2tracks_map = gt_meta_info.groupby(\"artistid\").agg(list)[\"trackid\"].to_dict()\n",
    "    ndcg_list = []\n",
    "    for query_trackid in tqdm(submission.keys()):\n",
    "        ranked_list = submission[query_trackid]\n",
    "        query_artistid = track2artist_map[query_trackid]\n",
    "        query_artist_tracks_count = len(artist2tracks_map[query_artistid])\n",
    "        ideal_dcg = get_ideal_dcg(query_artist_tracks_count - 1, top_size=top_size)\n",
    "        dcg = compute_dcg(\n",
    "            query_trackid, ranked_list, track2artist_map, top_size=top_size\n",
    "        )\n",
    "        try:\n",
    "            ndcg_list.append(dcg / ideal_dcg)\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "    return np.mean(ndcg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af9dffa-246d-461e-be44-9a58e4712eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = val_df[\"trackid\"].values\n",
    "embeds = {}\n",
    "for n, t in enumerate(tracks):\n",
    "    embeds[t] = predictions[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d879b188-1ee7-4743-b4cb-bc8c29ee52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_list(embeds, top_size, annoy_num_trees=128):\n",
    "    annoy_index = None\n",
    "    annoy2id = []\n",
    "    id2annoy = dict()\n",
    "    for track_id, track_embed in tqdm(embeds.items()):\n",
    "        id2annoy[track_id] = len(annoy2id)\n",
    "        annoy2id.append(track_id)\n",
    "        if annoy_index is None:\n",
    "            annoy_index = annoy.AnnoyIndex(len(track_embed), \"euclidean\")\n",
    "        annoy_index.add_item(id2annoy[track_id], track_embed)\n",
    "    annoy_index.build(annoy_num_trees, n_jobs=-1)\n",
    "    ranked_list = dict()\n",
    "    for track_id in tqdm(embeds.keys()):\n",
    "        candidates = annoy_index.get_nns_by_item(id2annoy[track_id], top_size + 1)[\n",
    "            1:\n",
    "        ]  # exclude trackid itself\n",
    "        candidates = list(filter(lambda x: x != id2annoy[track_id], candidates))\n",
    "        ranked_list[track_id] = [annoy2id[candidate] for candidate in candidates]\n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96041323-d8b0-463d-bd38-56289fd66d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20837/20837 [00:04<00:00, 4398.25it/s]\n",
      "100% 20837/20837 [00:45<00:00, 453.66it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = get_ranked_list(embeds, 100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be9b4096-ddf2-4130-a5f9-4e491178d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20837/20837 [00:07<00:00, 2966.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07843049426700441"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ev_sub(submission, gt_meta_info=val_df, top_size=100)\n",
    "ndcg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
