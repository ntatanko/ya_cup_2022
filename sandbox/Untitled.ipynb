{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14299a1d-8ec7-4ed0-96e1-ce81fa0af3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc23e1a-2855-48cb-956b-67a021d80f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random as rnd\n",
    "import shutil\n",
    "from itertools import combinations\n",
    "\n",
    "import albumentations as A\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.model_selection import StratifiedGroupKFold, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, activations, layers, losses\n",
    "from tensorflow.keras.utils import Progbar, plot_model\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tqdm import tqdm\n",
    "\n",
    "from _data.artist_data.ny_baseline import eval_submission as ev_sub\n",
    "from _data.artist_data.ny_baseline import get_ranked_list, inference\n",
    "from src.test_utils import (\n",
    "    TestGenerator,\n",
    "    choose_100,\n",
    "    eval_submission,\n",
    "    load_submission,\n",
    "    pairwise_distances,\n",
    ")\n",
    "from src.utils import make_callbacks, plot_history\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d841314c-f269-4b69-89fd-f726d78bb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.seed = 39\n",
    "        self.batch_size = 8\n",
    "        self.img_size = (512, 60)\n",
    "        self.n_folds = 8\n",
    "        self.fold = 0\n",
    "        self.norm = False\n",
    "        self.n_blocks = 4\n",
    "        self.emb_len = 1024\n",
    "        self.kernel_size = (5, 2)\n",
    "        self.batch_norm = False\n",
    "        self.n_epochs = 300\n",
    "        self.n_pairs_in_batch = 100\n",
    "        self.input_shape = (self.img_size[0], self.img_size[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93f6112-f03e-4df9-8e75-77aade00c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d157d3-7015-4828-bc9d-d688dfbafb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/_data/artist_data/models/test_arch/tripl_semi_hard_8_0/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"/app/_data/artist_data/\"\n",
    "mod_dir = f\"/app/_data/artist_data/models/test_arch/tripl_semi_hard_8_{cfg.fold}/\"\n",
    "mod_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46771e08-5acb-444d-a2b9-bb6bb8f4df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(root_dir, \"train.csv\"))\n",
    "train = train[train[\"artistid_count\"] != 1].reset_index(drop=True)\n",
    "test = pd.read_csv(os.path.join(root_dir, \"test_meta.tsv\"), sep=\"\\t\")\n",
    "test[\"path\"] = test[\"archive_features_path\"].apply(\n",
    "    lambda x: os.path.join(root_dir, \"test_features\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b35fc-281b-4c45-afb4-286bfd2eef13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e5bb09-cd8b-4cc3-af39-acc73ee0b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = StratifiedGroupKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "for n, (train_ids, val_ids) in enumerate(\n",
    "    gkf.split(\n",
    "        X=train[[\"artistid\", \"artistid_count\"]],\n",
    "        y=train[\"artistid_count\"],\n",
    "        groups=train[\"artistid\"],\n",
    "    )\n",
    "):\n",
    "    train.loc[val_ids, \"fold\"] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6761a2-a078-4863-a487-dd397cd1f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[train[\"fold\"] != cfg.fold].reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == cfg.fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aae54a-8be1-48e7-b74a-fb519b745a3f",
   "metadata": {},
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0ef5c5-7498-4652-be03-44a48be62df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        img_size,\n",
    "        batch_size=32,\n",
    "        n_pairs_in_batch=50,\n",
    "        norm=False,\n",
    "        shuffle=True,\n",
    "        transpose=True,\n",
    "        augment=True,\n",
    "    ):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_pairs_in_batch = n_pairs_in_batch\n",
    "        self.norm = norm\n",
    "        self.shuffle = shuffle\n",
    "        self.transpose = transpose\n",
    "        self.augment = augment\n",
    "        self.artist_ids = self.data[\"artistid\"].unique().tolist()\n",
    "        self.artis2path = self.data.groupby(\"artistid\").agg(list)[\"path\"].to_dict()\n",
    "        self.paths = self.data[\"path\"].tolist()\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.artist_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def augment_fn(self, img):\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.RandomCrop(always_apply=True, p=1.0, height=512, width=60),\n",
    "                A.Flip(p=0.2),\n",
    "                A.PixelDropout(p=0.1, dropout_prob=0.01),\n",
    "                A.CoarseDropout(\n",
    "                    p=0.1,\n",
    "                    max_holes=11,\n",
    "                    max_height=5,\n",
    "                    max_width=3,\n",
    "                    min_holes=1,\n",
    "                    min_height=2,\n",
    "                    min_width=2,\n",
    "                ),\n",
    "                A.RandomGridShuffle(p=0.3, grid=(1, 6)),\n",
    "            ]\n",
    "        )\n",
    "        return transform(image=img)[\"image\"]\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = np.load(path).astype(\"float32\")\n",
    "        if self.norm:\n",
    "            img -= img.min()\n",
    "            img /= img.max()\n",
    "        if self.augment:\n",
    "            img = self.augment_fn(img)\n",
    "        else:\n",
    "            wpad = (img.shape[1] - self.img_size[1]) // 2\n",
    "            img = img[:, wpad : wpad + self.img_size[1]]\n",
    "        if self.transpose:\n",
    "            img = img.transpose(1, 0)\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "\n",
    "    def get_list(self, artis_id):\n",
    "        valid_paths = self.artis2path[artis_id]\n",
    "        np.random.shuffle(valid_paths)\n",
    "        anchor_img = np.expand_dims(self.load_img(valid_paths[0]), 0)\n",
    "        positive_imgs = np.array([self.load_img(p) for p in valid_paths[1:]])\n",
    "        negative_paths = rnd.sample(\n",
    "            [x for x in self.paths if x not in valid_paths],\n",
    "            self.n_pairs_in_batch - len(positive_imgs),\n",
    "        )\n",
    "        negative_imgs = np.array([self.load_img(p) for p in negative_paths])\n",
    "        imgs = np.concatenate([positive_imgs, negative_imgs])\n",
    "        labels = np.full(self.n_pairs_in_batch, 10)\n",
    "        labels[positive_imgs.shape[0] :] = 0\n",
    "        perm = np.random.permutation(self.n_pairs_in_batch)\n",
    "        imgs = imgs[perm]\n",
    "        labels = labels[perm]\n",
    "        imgs = np.concatenate([anchor_img, imgs])\n",
    "        return imgs, labels\n",
    "\n",
    "    def __call__(self):\n",
    "        np.random.shuffle(self.artist_ids)\n",
    "        ix = 0\n",
    "        while ix < len(self.artist_ids):\n",
    "            tracks, labels = self.get_list(self.artist_ids[ix])\n",
    "            tracks = tf.convert_to_tensor(tracks)\n",
    "            labels = tf.convert_to_tensor(labels)\n",
    "            yield tracks, labels\n",
    "            ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e016b9-01bc-4a06-a8ba-0b308faa8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    data=train_df,\n",
    "    img_size=cfg.img_size,\n",
    "    batch_size=cfg.batch_size,\n",
    "    n_pairs_in_batch=cfg.n_pairs_in_batch,\n",
    "    norm=False,\n",
    "    shuffle=True,\n",
    "    transpose=False,\n",
    "    augment=True,\n",
    ")\n",
    "val_gen = DataGenerator(\n",
    "    data=val_df,\n",
    "    img_size=cfg.img_size,\n",
    "    batch_size=cfg.batch_size,\n",
    "    n_pairs_in_batch=cfg.n_pairs_in_batch,\n",
    "    norm=False,\n",
    "    shuffle=True,\n",
    "    transpose=False,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fadce01-aebc-4b7f-aa84-f1140fc3d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 512, 60, 1) (100,)\n",
      "(101, 512, 60, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "for n, (a, b) in enumerate(train_gen.__call__()):\n",
    "    print(a.shape, b.shape)\n",
    "    if n == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb38b1ac-16ed-498f-937d-7020c634f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(101, 512, 60, 1), dtype=tf.float32, name='tracks'), TensorSpec(shape=(100,), dtype=tf.float32, name='labels'))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    train_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch + 1, *cfg.img_size, 1),\n",
    "            dtype=tf.float32,\n",
    "            name=\"tracks\",\n",
    "        ),\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch),\n",
    "            dtype=tf.float32,\n",
    "            name=\"labels\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    val_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch + 1, *cfg.img_size, 1),\n",
    "            dtype=tf.float32,\n",
    "            name=\"tracks\",\n",
    "        ),\n",
    "        tf.TensorSpec(\n",
    "            shape=(cfg.n_pairs_in_batch),\n",
    "            dtype=tf.float32,\n",
    "            name=\"labels\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac82bfb7-3d67-4c56-b461-56d8b243965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0a2ce2-341d-498f-a77a-df079e568987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(101, 512, 60, 1), dtype=tf.float32, name='tracks'), TensorSpec(shape=(100,), dtype=tf.float32, name='labels'))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ade480a-cb01-41b3-b63c-e7ec99c9fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 512, 60, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "for example in train_ds.take(1):\n",
    "    print(example[0].shape, example[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3102230-894b-42e2-939c-715ca9cc82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embNet(\n",
    "    input_shape,\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.1,\n",
    "    embedding_len=1024,\n",
    "    activation_fn=\"relu\",\n",
    "    padding=\"same\",\n",
    "    dense_activation=\"relu\",\n",
    "):\n",
    "    base_model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                input_shape=input_shape,\n",
    "                padding=padding,\n",
    "                name=\"conv_1\",\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_2\",\n",
    "            ),\n",
    "            keras.layers.Dropout(rate=dropout_rate, name=\"dropout1\"),\n",
    "            keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2), strides=1, padding=\"same\", name=\"max_1\"\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_3\",\n",
    "            ),\n",
    "            keras.layers.Conv1D(\n",
    "                filters=1,\n",
    "                kernel_size=kernel_size,\n",
    "                activation=activation_fn,\n",
    "                padding=padding,\n",
    "                name=\"conv_4\",\n",
    "            ),\n",
    "            keras.layers.Flatten(name=\"flatten_base\"),\n",
    "            keras.layers.Dense(embedding_len * 2, activation=\"relu\", name=\"dense_1\"),\n",
    "            keras.layers.Dense(embedding_len, activation=None, name=\"dense_base_2\"),\n",
    "        ]\n",
    "    )\n",
    "    embedding_net = keras.Model(\n",
    "        inputs=base_model.input, outputs=base_model.output, name=\"embedding\"\n",
    "    )\n",
    "    return embedding_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb5ead15-f608-4821-9211-00f21caf1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = embNet(\n",
    "    input_shape=(512, 60, 1),\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.1,\n",
    "    embedding_len=1024,\n",
    "    activation_fn=\"relu\",\n",
    "    padding=\"valid\",\n",
    "    dense_activation=\"relu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3508bb7d-877a-4897-83b0-853daaa2f8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([101, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = embedding_net(example[0])\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ae5b58b-ea6e-473e-b051-16253e469ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_embeddings = emb[:1]\n",
    "img_embeddings = emb[1:]\n",
    "anchors_embeddings.shape\n",
    "list_length = img_embeddings.shape[0]\n",
    "anchors_embedding_repeated = tf.repeat(anchors_embeddings, [list_length], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4205120-3ae6-4e9c-8e94-bb6553022dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1024])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_embedding_repeated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60d184b4-147e-4ba2-87e1-47aae8312ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1024])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 2048])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors_embedding_repeated.shape\n",
    "\n",
    "concatenated_embeddings = tf.concat([anchors_embedding_repeated, img_embeddings], 1)\n",
    "\n",
    "concatenated_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "499492af-5c11-4370-ba82-9a8f6e9146d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = tf.keras.Sequential(\n",
    "    [\n",
    "        # Learn multiple dense layers.\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        # Make rating predictions in the final layer.\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores = score_model(concatenated_embeddings)\n",
    "\n",
    "scores.shape\n",
    "\n",
    "scores[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f659548-3f6f-4c9b-a099-4565a90cf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tfr.keras.losses.ListMLELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71977492-6f93-4e56-8194-4a305fe96458",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Ranking(\n",
    "    loss=loss,\n",
    "    metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d76d6f47-b0db-4237-8059-6272778d13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(scores, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6182b2c6-04e2-4f49-adcd-bd237e46f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([ 0., 10.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., 10.,  0., 10.,  0.,  0.,  0., 10.,  0., 10., 10.,  0.,  0.,\n",
       "        0., 10., 10.,  0.], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f5b1f29-282a-4d19-80c1-fbeaa7186217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(input_tensor=example[1], axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65b8d6b9-1fe7-47ab-8ebd-78a78e828b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=74.65823>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task(\n",
    "    labels=tf.expand_dims(example[1], 0),\n",
    "    predictions=tf.expand_dims(tf.squeeze(scores, axis=-1),0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3f9dd6-8443-4435-8625-07399c5764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.Model):\n",
    "    def __init__(self, loss, emb_model):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # embeddings model\n",
    "        self.embeddings = emb_model\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.score_model = tf.keras.Sequential(\n",
    "            [\n",
    "                # Learn multiple dense layers.\n",
    "                tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                # Make rating predictions in the final layer.\n",
    "                tf.keras.layers.Dense(1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=loss,\n",
    "            metrics=[\n",
    "                tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "                tf.keras.metrics.RootMeanSquaredError(),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        # batch_anchors = features[:1]\n",
    "        # batch_tracks = features[1:]\n",
    "        # We first convert the id features into embeddings.\n",
    "        # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "        embeddings = self.embeddings(features)\n",
    "        anchors_embeddings = embeddings[:1, ...]\n",
    "        img_embeddings = embeddings[1:, ...]\n",
    "        # anchors_embeddings = self.embeddings(batch_anchors)\n",
    "\n",
    "        # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "        # tensor.\n",
    "        # img_embeddings = tf.convert_to_tensor(\n",
    "        #     [self.embeddings(x) for x in batch_tracks]\n",
    "        # )\n",
    "\n",
    "        # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "        # them into the ranking model. To do so, we need to reshape the user\n",
    "        # embeddings to match the shape of movie embeddings.\n",
    "\n",
    "        list_length = img_embeddings.shape[0]\n",
    "        anchors_embedding_repeated = tf.repeat(\n",
    "            anchors_embeddings, [list_length], axis=0\n",
    "        )\n",
    "\n",
    "        # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "        # predictions.\n",
    "        concatenated_embeddings = tf.concat(\n",
    "            [anchors_embedding_repeated, img_embeddings], 1\n",
    "        )\n",
    "\n",
    "        return self.score_model(concatenated_embeddings)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        features, labels = features\n",
    "        # labels = features[\"labels\"]\n",
    "        scores = self(features)\n",
    "\n",
    "        return self.task(\n",
    "            labels=tf.expand_dims(labels, 0),\n",
    "            predictions=tf.expand_dims(tf.squeeze(scores, axis=-1), 0),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ef84d6-9a11-47a1-b9c0-46499a66447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss(), embedding_net)\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceaea417-598e-43ca-bfff-1993d93fe0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = RankingModel(tf.keras.losses.MeanSquaredError(), embedding_net)\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19be881e-3acd-47ed-8519-9f5c2a2f2547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 15844/146356 [==>...........................] - ETA: 5:14:05 - ndcg_metric: 0.4184 - root_mean_squared_error: 2.7248 - loss: 7.4241 - regularization_loss: 0.0000e+00 - total_loss: 7.4241"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmse_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__len__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__len__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = mse_model.fit(\n",
    "    x=train_ds,\n",
    "    epochs=10,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    steps_per_epoch=train_gen.__len__(),\n",
    "    validation_steps=val_gen.__len__(),\n",
    "    validation_freq=1,\n",
    "    max_queue_size=100,\n",
    "    workers=64,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afa492-d0cb-4513-8ad5-e6f679ff5559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
